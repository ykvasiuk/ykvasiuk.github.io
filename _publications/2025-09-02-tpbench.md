---
title: "Theoretical physics benchmark (TPBench) â€” a dataset and study of AI reasoning capabilities in theoretical physics"
collection: "publications"
category: "manuscripts"
venue: "Mach. Learn.: Sci. Technol. 6"
date: "2025-09-02"
links:
  - label: "Journal"
    url: "https://iopscience.iop.org/article/10.1088/2632-2153/adfcb0"
  - label: "arXiv"
    url: "https://arxiv.org/abs/2502.15815"
excerpt: ''
abstract: "We introduce a benchmark to evaluate the capability of AI to solve problems in theoretical physics (TP), focusing on high-energy theory and cosmology. The first iteration of our benchmark consists of 57 problems of varying difficulty, from undergraduate to research level. These problems are novel in the sense that they do not come from public problem collections. We evaluate our data set on various open and closed language models, including o3-mini, o1, DeepSeek-R1, GPT-4o and versions of Llama and Qwen. While we find impressive progress in model performance with the most recent models, our research-level difficulty problems are mostly unsolved. We address challenges of auto-verifiability and grading, and discuss common failure modes. While currently state-of-the art models are still of limited use for researchers, our results show that AI assisted TP research may become possible in the near future. We discuss the main obstacles towards this goal and possible strategies to overcome them. The public problems and solutions, results for various models, and updates to the data set and score distribution, are available on the website of the dataset [tpbench.org](https://tpbench.org/)."   
--- 